<html>
<head>
<title>Workspace view</title>
<link type="text/css" href="css/workspacestyle.css" rel="stylesheet"></link>

<link href="../css/lib/jquery-ui.css" rel="stylesheet" type="text/css" />
<script src="../js/lib/jquery.min.js"></script>
<script	src="../js/lib/jquery-ui.min.js"></script>

<script src="js/lib/sylvester.js"></script>
<script type="text/javascript" src="js/mediaext.js"></script>
<script type="text/javascript" src="js/geometry.js"></script>
<script type="text/javascript" src="js/lib/cv.js"></script>
<script type="text/javascript" src="js/lib/aruco.js"></script>
<script type="text/javascript" src="js/imageproc.js"></script>
<script type="text/javascript" src="js/buttons.js"></script>
<script type="text/javascript" src="js/calibration.js"></script>
<script type="text/javascript" src="js/lib/pixastic.core.js"></script>
<script type="text/javascript" src="js/lib/blend.js"></script>
<script type="text/javascript" src="js/utilities.js"></script>
<script type="text/javascript" src="js/videoBucket.js"></script>
<script type="text/javascript" src="js/optimus.js"></script>

<script src="/webrtc.io.js"></script>
</head>
<body style="font-family: monospace; background-color: white;">
<div id="notice">This is the workspace view. Choose the appropriate camera and move this window to where you want it.</div>
<div>
<button id="fullscreen">Enter Full Screen</button>
</div>
<center>
<canvas id ="myCanvas" style="width: 100%; height: 100%"></canvas>
<video id="you" autoplay></video>
</center>
<script>

// What???
// const CANVAS_WIDTH = 640, CANVAS_HEIGHT = 360;
const CANVAS_WIDTH = 800, CANVAS_HEIGHT = 600;
// const CANVAS_WIDTH = 1920, CANVAS_HEIGHT = 1080;

// hide and show correct html elements
var c = $('#myCanvas');
c.hide();

var fullscreen = $('#fullscreen');
fullscreen.hide();

var notice = $('#notice');

$('#you').hide();

function Workspace() {
	
	var video, screenCanvas, screenContext;
	var calibrator;
	var sharedRect, sharedPoly;
	var sharedTransformer, sharedTransformerEnc;
	var videos = [];
	var videoObj;
	var PeerConnection = window.webkitRTCPeerConnection;
	var buttons;
	var cb, cs;

	var logo;
	
	var self = this; // Used to avoid faulty this-references in anonymous functions and callbacks

	this.createVideo = function (stream, socketId) {
		fullscreen.show();
		
		var v = document.createElement('video');
		v.width = CANVAS_WIDTH;
		v.height = CANVAS_HEIGHT;
		v.autoplay = true;
		v.class = "";
		v.src = URL.createObjectURL(stream);

		if (socketId == 'you') {
			videoObj = new VideoBucket(v, stream.label);
			v.id = 'you';
			video = v;

			// *****
			// Test - draw own video
			// videos.push(videoObj);
			// *****

		} else {
			v.id = 'remote' + socketId;
			var bucket = new VideoBucket(v, stream.label);
			videos.push(bucket);
		}
	}

	this.removeVideo = function (socketId) {
		var index = -1;
		for (var i = 0; i < videos.length; i++) {
			if (videos[i].video.id == 'remote' + socketId) {
				console.log('Removing stream: ' + videos[i].label);
				index = i;
				break;
			}
		}
		if (index > -1) {
			videos.splice(index, 1);
		}
	}

	this.initFullScreen = function () {
		fullscreen.click(function(event) {
				
				var element = document.body;
				var requestMethod = element.requestFullScreen || element.webkitRequestFullScreen || element.mozRequestFullScreen || element.msRequestFullScreen;
				if (requestMethod) {
					// TODO enter full screen
					requestMethod.call(element);
				}
				notice.hide();
				fullscreen.remove();
				self.startCalibration();
			});
	}

	this.init = function () {
		
		// Load LTU logo image
		logo = new Image();
		logo.src = "../img/ltu_logo.jpg";
		
		// TODO change to c...
		screenCanvas = document.getElementById("myCanvas");
		screenContext = screenCanvas.getContext("2d");

		screenCanvas.width = window.innerWidth;
		screenCanvas.height = window.innerHeight;

		// Resize the fullscreen canvas when the window is resized
		// This is necessary to keep its image data in the same dimensions as its actual size
		window.onresize = function() {
			screenCanvas.width = window.innerWidth;
			screenCanvas.height = window.innerHeight;
			
			self.drawLogo();
		};

		if (PeerConnection) {
			rtc.createStream({"video": true, "audio": true}, function(stream) {
					self.createVideo(stream, 'you');
					rtc.attachStream(stream, 'you');
				});
		} else {
			alert('Your browser is not supported or you have to turn on flags. In chrome you go to chrome://flags and turn on Enable PeerConnection remember to restart chrome');
		}

		var room = window.location.hash.slice(1);

		// When using localhost
		console.log('Connecting');
		rtc.connect("ws://"+ window.location.host +"/", room);

		rtc.on('add remote stream', function(stream, socketId) {
				console.log("ADDING REMOTE STREAM...");
				self.createVideo(stream, socketId);
			});
		rtc.on('disconnect stream', function(data) {
				console.log('remove ' + data);
				self.removeVideo(data);
				buttons.deleteButtonId('remote' + data);
			});

		this.initFullScreen();
	}

	this.startCalibration = function () {
		// start showing fullscreen canvas
		c.show();

		// Show the qr codes on sifteos
		var tangibles2 = window.opener.parent.tangibles;
		if (tangibles2.sifteos.length > 2) {
			tangibles2.showPicture(tangibles2.sifteos[0],"http://"+ window.location.host +"/img/sifteo_qr188.png");
			tangibles2.showPicture(tangibles2.sifteos[2],"http://"+ window.location.host +"/img/sifteo_qr956.png");
		}
		
		// Force correct canvas dimensions before initiating calibration
		screenCanvas.width = window.innerWidth;
		screenCanvas.height = window.innerHeight;
		
		// Create Calibrator object and start calibration
		calibrator = new Calibrator(video, screenCanvas);
		calibrator.startCalibration(this.onGotTransform, this.onFinishedCalibration, self);
	}


	/**
	 Callback from Calibrator when the camera->screen transform is found
	 @param trans the transform object
	 */
	this.onGotTransform = function (transform) {
		console.log('got transform');
		// transform = trans;
		var inverse = transform.inverse();

		// enable calibration buttons
		var width = window.innerWidth;
		var height = window.innerHeight;
		buttons = new Buttons(screenContext, inverse, video, width, height);
		buttons.start();
		img = new Image();
		img.src = "img/doneButton.png";
		var calibratorButton = new Button(img, calibrator.confirmSharedRectangle, calibrator);
		//var calibratorButton = new Button(img, this.buttonPressed);
		calibratorButton.id = 'done';
		buttons.addButton(calibratorButton);

		$(document).keypress(function(event) {
			var keycode = (event.keyCode ? event.keyCode : event.which);
			if (keycode == 13) {
				calibrator.confirmSharedRectangle();
			}
			// TODO remove keypress
		});
		screenCanvas.onclick = function() {
			calibrator.confirmSharedRectangle();
		};
	}

	/** 
	 Callback from Calibrator when calibration finishes.
	 @param sRect the rectangle in the screenCanvas that will be shared with the others
	 @param sTransformer the transformer object that manages the transform polys
	 */
	this.onFinishedCalibration = function (sRect, sTransformer) {
		
		console.log('finished calibration');
		buttons.deleteButtonId('done');
		sharedRect = sRect;
		
		// sharedPoly = sPoly;
		sharedTransformer = sTransformer;
		sharedTransformerEnc = sTransformer.encode();
		
		videoObj.setTransform(sTransformer, sRect);

		// Remove qr codes from sifteos when done
		var tangibles2 = window.opener.parent.tangibles;
		if (tangibles2.sifteos.length > 2) {
			setTimeout(tangibles2.setColor(tangibles2.sifteos[0],"FFFFFF"),10000);
			setTimeout(tangibles2.setColor(tangibles2.sifteos[2],"FFFFFF"),10000);
		}
		
		// setup listener and broadcast your coordinates
		window.opener.parent.socket.on(window.opener.parent.API_CORNERS, self.onGotCorners);
		self.sendBroadcast();
		window.opener.parent.socket.on(window.opener.parent.API_CORNERS_BROADCAST, self.onBroadcast);

		// start merging incoming videos in workspace
		self.mergeVideos();

	}

	/**
	 Called from the server when someone broadcasts their transform
	 */
	this.onBroadcast = function (id, nw, ne, se, sw, label) {
		console.log('got broadcast, ' + label);

		// Changed API, server might need an update :)
		var polyList = nw;
		var depth = ne;
		
		for (var i = 0; i < videos.length; i++) {
			var v = videos[i];
			if (v.label == label) {
				
				var dstRect = new Geometry.Rectangle(0, 0, sharedRect.width, sharedRect.height);
				var transformer = Transformers.OptimusPrime.decode(dstRect, polyList, depth);
				v.setTransform(/*[nw, ne, se, sw]*/ transformer, sharedRect);

				// enable buttons
				b = new VideoButton(v, v.toggleEnabled, v);
				b.id = v.video.id;
				buttons.addButton(b);
			}
		}

		// answer broadcast
		self.answerBroadcast(id);
	}

	/**
	 Called from the server when someone sends their transform
	 @param nw, ne, se, sw - used to be the corners of the shared rectangle in the camera's view
			Now, nw is a list of polygons and ne is the calibration depth of OptimusPrime
	 */
	this.onGotCorners = function (nw, ne, se, sw, label) {
		console.log('got corners, ' + label);

		// Changed API, server might need an update :)
		var polyList = nw;
		var depth = ne;
		
		for (var i = 0; i < videos.length; i++) {
			var v = videos[i];
			if (v.label == label) {
				
				var dstRect = new Geometry.Rectangle(0, 0, sharedRect.width, sharedRect.height);
				var transformer = Transformers.OptimusPrime.decode(dstRect, polyList, depth);
				v.setTransform(/*[nw, ne, se, sw]*/ transformer, sharedRect);

				// enable buttons
				b = new VideoButton(v, v.toggleEnabled, v);
				b.id = v.video.id;
				buttons.addButton(b);
			}
		}
	}

	/**
	 Send transform information to all participants
	 */
	this.sendBroadcast = function () {
		// data to broadcast
		var data = JSON.stringify({
			nw: sharedTransformerEnc, // sharedPoly[0],
			ne: sharedTransformer.depth, // sharedPoly[1],
			se: 0, // sharedPoly[2],
			sw: 0, // sharedPoly[3],
			videoLabel: videoObj.label
		});

		console.log('Sending broadcast, ' + videoObj.label);
		console.log(data);
		window.opener.parent.socket.send(window.opener.parent.API_CORNERS_BROADCAST, data);
	}

	/**
	 Send local transform in response to broadcast
	 */
	this.answerBroadcast = function (id) {
		var data = JSON.stringify({
			id: id, // to who we are going to send
			nw: sharedTransformerEnc, // sharedPoly[0],
			ne: sharedTransformer.depth, // sharedPoly[1],
			se: 0, // sharedPoly[2],
			sw: 0, // sharedPoly[3],
			videoLabel: videoObj.label
		});

		console.log('Sending broadcast reply');
		console.log(data);
		window.opener.parent.socket.send(window.opener.parent.API_CORNERS, data);
	}

	/**
	 Merges the incoming video streams and draws them to screen
	 */
	this.mergeVideos = function () {

		var transformedVideos = VideoBucket.transformList(videos);
		var mergedImage = Utilities.mergeImages(transformedVideos);

		/*
		var localVideo = videoObj.transformVideo();
		if (localVideo != null) {
			Utilities.filterDifference(localVideo, mergedImage);
		}
		 */
		
		// Draw a fram around the shared rectangle
		sharedRect.draw(screenContext);
		
		if (mergedImage != null) {
			// console.log('drawing merged videos, ' + sharedRect.x + ' ' + sharedRect.width);
			screenContext.drawImage(mergedImage,
									sharedRect.x,
									sharedRect.y,
									sharedRect.width,
									sharedRect.height);
		} else {
			// If no video is available yet, just clear the area
			screenContext.clearRect(sharedRect.x, sharedRect.y, sharedRect.width, sharedRect.height);
		}

		// *****
		// Test - check if canvas dimensions are correct
		// var rect = new Geometry.Rectangle(0, 0, screenCanvas.width, screenCanvas.height);
		// rect.draw(screenContext);
		// *****
		
		self.drawLogo();
		
		setTimeout(function() {self.mergeVideos();}, 1); // 50);
	}
	
	this.drawLogo = function() {
		screenContext.drawImage(logo,
								0, screenCanvas.height - logo.height,
								logo.width, logo.height);
	}
}

workspace = new Workspace();
workspace.init();

</script>
</body>
</html>
